{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#00008B'>  <center> Machine and Deep Learning Solutions for Bank Direct Marketing Campaigns </center> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries & Data Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #To filter the future warnings. \n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Removes the limit from the number of displayed columns and rows.\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Library to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>marital_unknown</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>month_apr</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.405280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.231366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.350932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.234472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.476708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education  duration  campaign  pdays  previous  cons.price.idx  \\\n",
       "0  0.750000   0.285714  0.405280       0.0    0.0         0        0.698753   \n",
       "1  0.769231   0.714286  0.231366       0.0    0.0         0        0.698753   \n",
       "2  0.384615   0.714286  0.350932       0.0    0.0         0        0.698753   \n",
       "3  0.442308   0.428571  0.234472       0.0    0.0         0        0.698753   \n",
       "4  0.750000   0.714286  0.476708       0.0    0.0         0        0.698753   \n",
       "\n",
       "   cons.conf.idx  nr.employed  job_admin.  job_blue-collar  job_entrepreneur  \\\n",
       "0       0.685714     0.859735           0                0                 0   \n",
       "1       0.685714     0.859735           0                0                 0   \n",
       "2       0.685714     0.859735           0                0                 0   \n",
       "3       0.685714     0.859735           1                0                 0   \n",
       "4       0.685714     0.859735           0                0                 0   \n",
       "\n",
       "   job_housemaid  job_management  job_retired  job_services  job_student  \\\n",
       "0              1               0            0             0            0   \n",
       "1              0               0            0             1            0   \n",
       "2              0               0            0             1            0   \n",
       "3              0               0            0             0            0   \n",
       "4              0               0            0             1            0   \n",
       "\n",
       "   job_technician  job_unemployed  job_unknown  marital_divorced  \\\n",
       "0               0               0            0                 0   \n",
       "1               0               0            0                 0   \n",
       "2               0               0            0                 0   \n",
       "3               0               0            0                 0   \n",
       "4               0               0            0                 0   \n",
       "\n",
       "   marital_single  marital_unknown  housing_yes  default_no  default_yes  \\\n",
       "0               0                0            0           1            0   \n",
       "1               0                0            0           0            0   \n",
       "2               0                0            1           1            0   \n",
       "3               0                0            0           1            0   \n",
       "4               0                0            0           1            0   \n",
       "\n",
       "   loan_unknown  loan_yes  month_apr  month_dec  month_jul  month_jun  \\\n",
       "0             0         0          0          0          0          0   \n",
       "1             0         0          0          0          0          0   \n",
       "2             0         0          0          0          0          0   \n",
       "3             0         0          0          0          0          0   \n",
       "4             0         1          0          0          0          0   \n",
       "\n",
       "   month_mar  month_may  month_nov  month_oct  month_sep  contact_telephone  \\\n",
       "0          0          1          0          0          0                  1   \n",
       "1          0          1          0          0          0                  1   \n",
       "2          0          1          0          0          0                  1   \n",
       "3          0          1          0          0          0                  1   \n",
       "4          0          1          0          0          0                  1   \n",
       "\n",
       "   day_of_week_fri  day_of_week_mon  day_of_week_thu  day_of_week_wed  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                1                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                1                0                0   \n",
       "\n",
       "   poutcome_failure  poutcome_success  y  \n",
       "0                 0                 0  0  \n",
       "1                 0                 0  0  \n",
       "2                 0                 0  0  \n",
       "3                 0                 0  0  \n",
       "4                 0                 0  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Final Dataset for Prediction\n",
    "df = pd.read_csv(r\"datasets/processed_data_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35165, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Dataset Balancing using Synthetic Minority Oversampling (SMOTE) Technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35165, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw = df.drop(['y'], axis=1)\n",
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35165,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw = df['y']\n",
    "y_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32435\n",
       "1     2730\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Minority Oversampling (SMOTE) technique was used in this study to obtain a balanced dataset. This is due to its simplicity and effectiveness [Ref 1].\n",
    "# Ref 1: Chaurasia, Priyanka, et al. \"Modelling assistive technology adoption for people with dementia.\" Journal of biomedical informatics 63 (2016): 235-248.\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.4, random_state=100)\n",
    "under = RandomUnderSampler(sampling_strategy=1, random_state=100)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(X_raw, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25948, 44)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12974\n",
       "1    12974\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#00008B'> 5. Building and Tunning the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def partial_gini(y_actual, y_pred):\n",
    "    # If the predictions y_pred are binary class probabilities\n",
    "    if y_pred.ndim == 2:\n",
    "        if y_pred.shape[1] == 2:\n",
    "            y_pred = y_pred[:, 1]\n",
    "    gini = lambda a, p: 2 * metrics.roc_auc_score(a, p) - 1\n",
    "    return gini(y_actual, y_pred) / gini(y_actual, y_actual)\n",
    "\n",
    "\n",
    "def get_scores(y_test, y_pred):\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    brier_score = 1-metrics.brier_score_loss(y_test, y_pred)\n",
    "    gini = partial_gini(y_test, y_pred)\n",
    "    return auc, brier_score, gini\n",
    "\n",
    "acc_table= {}\n",
    "df_acc_kfold = pd.DataFrame()\n",
    "df_brier_kfold = pd.DataFrame()\n",
    "df_gini_kfold = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Conventional Methods\n",
    "#### 5.1.1 Model 1-1 : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.8924461705150808 , brier score =  0.892485549132948 , partial gini =  0.7848923410301616\n",
      "K =  2 , auc =  0.897525414660246 , brier score =  0.8971098265895954 , partial gini =  0.7950508293204921\n",
      "K =  3 , auc =  0.896094904646267 , brier score =  0.8959537572254335 , partial gini =  0.7921898092925339\n",
      "K =  4 , auc =  0.8971138208001634 , brier score =  0.8971098265895954 , partial gini =  0.7942276416003269\n",
      "K =  5 , auc =  0.8955768497409573 , brier score =  0.8955684007707129 , partial gini =  0.7911536994819146\n",
      "K =  6 , auc =  0.8951203039407515 , brier score =  0.8951830443159923 , partial gini =  0.790240607881503\n",
      "K =  7 , auc =  0.9021794954098993 , brier score =  0.902504816955684 , partial gini =  0.8043589908197986\n",
      "K =  8 , auc =  0.8938558944176922 , brier score =  0.8944123314065511 , partial gini =  0.7877117888353844\n",
      "K =  9 , auc =  0.8929046785951434 , brier score =  0.8928296067848882 , partial gini =  0.7858093571902869\n",
      "K =  10 , auc =  0.9003198814214203 , brier score =  0.899768696993061 , partial gini =  0.8006397628428406\n",
      "\n",
      "***  Conventional - Logistic Regression  ***\n",
      "\n",
      "AUC : 0.896 (0.003)\n",
      "Brier Score : 0.896 (0.003)\n",
      "Partial Gini : 0.793 (0.006)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "model_1_1 = LogisticRegression(random_state=1)\n",
    "\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # defining the model\n",
    "    model = LogisticRegression(random_state=1)\n",
    "    model.fit(X_train,y_train)\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the result\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1\n",
    "    \n",
    "df_acc_kfold[\"Conv-Logistic\"]=result_acc\n",
    "df_brier_kfold[\"Conv-Logistic\"]=result_brier\n",
    "df_gini_kfold[\"Conv-Logistic\"]=result_gini\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  Conventional - Logistic Regression  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Model 1-2 : Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.8861606188192916 , brier score =  0.8863198458574181 , partial gini =  0.7723212376385833\n",
      "K =  2 , auc =  0.8856607811663991 , brier score =  0.8840077071290944 , partial gini =  0.7713215623327982\n",
      "K =  3 , auc =  0.8862613281565578 , brier score =  0.8859344894026975 , partial gini =  0.7725226563131156\n",
      "K =  4 , auc =  0.8863282934542557 , brier score =  0.8863198458574181 , partial gini =  0.7726565869085114\n",
      "K =  5 , auc =  0.8898067485354968 , brier score =  0.8897880539499037 , partial gini =  0.7796134970709936\n",
      "K =  6 , auc =  0.8627152230550179 , brier score =  0.8628131021194605 , partial gini =  0.7254304461100358\n",
      "K =  7 , auc =  0.845943627713224 , brier score =  0.8477842003853564 , partial gini =  0.6918872554264479\n",
      "K =  8 , auc =  0.8818129124308899 , brier score =  0.8832369942196532 , partial gini =  0.7636258248617798\n",
      "K =  9 , auc =  0.8798687189876548 , brier score =  0.8797224363916731 , partial gini =  0.7597374379753097\n",
      "K =  10 , auc =  0.88435138658901 , brier score =  0.8831919814957594 , partial gini =  0.76870277317802\n",
      "\n",
      "***  Conventional - Decision Tree  ***\n",
      "\n",
      "AUC : 0.879 (0.013)\n",
      "Brier Score : 0.879 (0.013)\n",
      "Partial Gini : 0.758 (0.026)\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Libraries \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    dtree_estimator = DecisionTreeClassifier(random_state=1) \n",
    "    # Grid of parameters to choose from\n",
    "    parameters = {\"ccp_alpha\": [0.01, 0.1, 0.2, 0.3, 0.4, 0.5], \n",
    "              'min_samples_leaf': [3, 4, 5, 6, 7,8]}\n",
    "    acc_scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "    # Running the grid search\n",
    "    grid_obj = GridSearchCV(dtree_estimator, parameters, scoring=acc_scorer, cv=cv_inner, refit=True)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "    # Set the clf to the best combination of parameters\n",
    "    model_1_2 = grid_obj.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_1_2.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the result\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1\n",
    "    \n",
    "df_acc_kfold[\"Conv-DecisionTree\"]=result_acc\n",
    "df_brier_kfold[\"Conv-DecisionTree\"]=result_brier\n",
    "df_gini_kfold[\"Conv-DecisionTree\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  Conventional - Decision Tree  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ensemble Methods\n",
    "#### 5.2.1 Model 2-1 : Randome Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.9432565828553506 , brier score =  0.9433526011560693 , partial gini =  0.8865131657107013\n",
      "K =  2 , auc =  0.9393124665596577 , brier score =  0.9387283236994219 , partial gini =  0.8786249331193154\n",
      "K =  3 , auc =  0.9419632461613767 , brier score =  0.941811175337187 , partial gini =  0.8839264923227534\n",
      "K =  4 , auc =  0.9410480271528583 , brier score =  0.9410404624277456 , partial gini =  0.8820960543057166\n",
      "K =  5 , auc =  0.937967551051199 , brier score =  0.9379576107899807 , partial gini =  0.875935102102398\n",
      "K =  6 , auc =  0.9428730028048942 , brier score =  0.9429672447013487 , partial gini =  0.8857460056097883\n",
      "K =  7 , auc =  0.9481063605172869 , brier score =  0.948747591522158 , partial gini =  0.8962127210345738\n",
      "K =  8 , auc =  0.9429329409666488 , brier score =  0.9437379576107899 , partial gini =  0.8858658819332976\n",
      "K =  9 , auc =  0.936838400825589 , brier score =  0.9367771781033154 , partial gini =  0.873676801651178\n",
      "K =  10 , auc =  0.9424284816993092 , brier score =  0.9417887432536622 , partial gini =  0.8848569633986183\n",
      "\n",
      "***  Ensemble - RandomForest  ***\n",
      "\n",
      "AUC : 0.942 (0.003)\n",
      "Brier Score : 0.942 (0.003)\n",
      "Partial Gini : 0.883 (0.006)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    rf_estimator_weighted = RandomForestClassifier(random_state=1)\n",
    "    # Grid of parameters to choose from\n",
    "    parameters= {\"n_estimators\": [100, 250, 500, 750], \"max_samples\": [0.1, 0.5, 1, 4]}\n",
    "    # Type of scoring used to compare parameter combinations\n",
    "    acc_scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "    # # Run the grid search\n",
    "    grid_obj = GridSearchCV(rf_estimator_weighted, parameters, scoring=acc_scorer, cv=cv_inner, refit=True)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "    # Set the clf to the best combination of parameters\n",
    "    model_2_1 = grid_obj.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_2_1.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the results\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1\n",
    "    \n",
    "df_acc_kfold[\"Ensemble-RandomForest\"]=result_acc\n",
    "df_brier_kfold[\"Ensemble-RandomForest\"]=result_brier\n",
    "df_gini_kfold[\"Ensemble-RandomForest\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  Ensemble - RandomForest  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Model 2-2 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.9441315644409385 , brier score =  0.9441233140655106 , partial gini =  0.888263128881877\n",
      "K =  2 , auc =  0.941729088639201 , brier score =  0.941811175337187 , partial gini =  0.883458177278402\n",
      "K =  3 , auc =  0.9417939475447542 , brier score =  0.941811175337187 , partial gini =  0.8835878950895084\n",
      "K =  4 , auc =  0.9398837901379621 , brier score =  0.9398843930635838 , partial gini =  0.8797675802759242\n",
      "K =  5 , auc =  0.9364181060239761 , brier score =  0.9364161849710982 , partial gini =  0.8728362120479523\n",
      "K =  6 , auc =  0.9417743895702132 , brier score =  0.941811175337187 , partial gini =  0.8835487791404264\n",
      "K =  7 , auc =  0.9395690227044147 , brier score =  0.9394990366088632 , partial gini =  0.8791380454088293\n",
      "K =  8 , auc =  0.9414169787765293 , brier score =  0.941811175337187 , partial gini =  0.8828339575530586\n",
      "K =  9 , auc =  0.9421903432008099 , brier score =  0.9421742482652274 , partial gini =  0.8843806864016197\n",
      "K =  10 , auc =  0.9365120434344012 , brier score =  0.9363916730917502 , partial gini =  0.8730240868688024\n",
      "\n",
      "***  Ensemble - XGBClassifier  ***\n",
      "\n",
      "AUC : 0.941 (0.002)\n",
      "Brier Score : 0.941 (0.002)\n",
      "Partial Gini : 0.881 (0.005)\n"
     ]
    }
   ],
   "source": [
    "## XGBoost libary for building XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    model = XGBClassifier(random_state=1)\n",
    "    # Grid of parameters to choose from\n",
    "    parameters = {\n",
    "                 \"n_estimators\": [50, 100, 150],\n",
    "                 \"max_depth\":[1, 2, 3],\n",
    "                 \"learning_rate\":[0.3, 0.4],\n",
    "                 \"colsample_bytree\":[0.5, 0.75, 1],\n",
    "                 \"subsample\":[0.6, 0.8]\n",
    "     }\n",
    "    # Type of scoring used to compare parameter combinations\n",
    "    acc_scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "    # # Run the grid search\n",
    "    grid_obj = GridSearchCV(model, parameters, scoring=acc_scorer, cv=cv_inner, refit=True)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "    # Set the clf to the best combination of parameters\n",
    "    model_2_2 = grid_obj.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_2_2.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the results\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1    \n",
    "    \n",
    "df_acc_kfold[\"Ensemble-XGB\"]=result_acc\n",
    "df_brier_kfold[\"Ensemble-XGB\"]=result_brier\n",
    "df_gini_kfold[\"Ensemble-XGB\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  Ensemble - XGBClassifier  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Multilayer Perceptron Neural Networks - MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Model 3-1 : MLP with one hidden layer - MLP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def create_model_one_hidden_layer(units, dropout_rate, L2, batch_normalization = \"yes\"):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units = units, kernel_regularizer=l2(l=L2)))\n",
    "    if batch_normalization == \"yes\":\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.8950877476441433 , brier score =  0.8951830443159923 , partial gini =  0.7901754952882867\n",
      "K =  2 , auc =  0.8954744069912609 , brier score =  0.8951830443159923 , partial gini =  0.7909488139825218\n",
      "K =  3 , auc =  0.8919488706297195 , brier score =  0.8917148362235068 , partial gini =  0.783897741259439\n",
      "K =  4 , auc =  0.8948097007079273 , brier score =  0.8947976878612717 , partial gini =  0.7896194014158546\n",
      "K =  5 , auc =  0.894804651720873 , brier score =  0.8947976878612717 , partial gini =  0.789609303441746\n",
      "K =  6 , auc =  0.8928054643757062 , brier score =  0.8928709055876686 , partial gini =  0.7856109287514124\n",
      "K =  7 , auc =  0.901045344632043 , brier score =  0.9021194605009634 , partial gini =  0.802090689264086\n",
      "K =  8 , auc =  0.8877519172462993 , brier score =  0.8882466281310212 , partial gini =  0.7755038344925986\n",
      "K =  9 , auc =  0.8952747990272222 , brier score =  0.8951426368542791 , partial gini =  0.7905495980544444\n",
      "K =  10 , auc =  0.9005595843087992 , brier score =  0.899768696993061 , partial gini =  0.8011191686175985\n",
      "\n",
      "***  MLP with one hidden layer - MLP1  ***\n",
      "\n",
      "AUC : 0.895 (0.004)\n",
      "Brier Score : 0.895 (0.004)\n",
      "Partial Gini : 0.790 (0.007)\n"
     ]
    }
   ],
   "source": [
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    model = KerasClassifier(model=create_model_one_hidden_layer, epochs=10, batch_size=64, verbose=0)\n",
    "    # Grid of parameters to choose from\n",
    "    units = [5, 10, 15, 20]\n",
    "    dropout_rate = [0, 0.25, 0.5]\n",
    "    L2 = [0.1,0.001, 0]\n",
    "    batch_normalization = [\"yes\"]\n",
    "    learning_rate = [0.01, 0.001, 0.0001]\n",
    "    param_grid = dict(model__units=units, model__dropout_rate = dropout_rate,\n",
    "                      model__batch_normalization = batch_normalization, optimizer__learning_rate=learning_rate, \n",
    "                      model__L2 = L2)\n",
    "    # Running the grid search\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_inner, refit=True)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model_3_1 = grid_result.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_3_1.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the results\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1    \n",
    "    \n",
    "df_acc_kfold[\"MLP - MLP1\"]=result_acc\n",
    "df_brier_kfold[\"MLP - MLP1\"]=result_brier\n",
    "df_gini_kfold[\"MLP - MLP1\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  MLP with one hidden layer - MLP1  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Model 3-2 : MLP with Three hidden layers - MLP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_three_hidden_layers(units_1, units_2, units_3, dropout_rate, L2, batch_normalization = \"yes\"):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units = units_1, kernel_regularizer=l2(l=L2)))\n",
    "    model.add(Dense(units = units_2, kernel_regularizer=l2(l=L2)))\n",
    "    model.add(Dense(units = units_3, kernel_regularizer=l2(l=L2)))\n",
    "    if batch_normalization == \"yes\":\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.8966562397532706 , brier score =  0.8967244701348748 , partial gini =  0.7933124795065412\n",
      "K =  2 , auc =  0.883458177278402 , brier score =  0.8836223506743738 , partial gini =  0.7669163545568041\n",
      "K =  3 , auc =  0.8843981523283608 , brier score =  0.8843930635838151 , partial gini =  0.7687963046567217\n",
      "K =  4 , auc =  0.8770586502216208 , brier score =  0.8770712909441233 , partial gini =  0.7541173004432415\n",
      "K =  5 , auc =  0.8940419576764205 , brier score =  0.8940269749518305 , partial gini =  0.788083915352841\n",
      "K =  6 , auc =  0.8782659909259714 , brier score =  0.8782273603082852 , partial gini =  0.7565319818519427\n",
      "K =  7 , auc =  0.8997016612812337 , brier score =  0.9001926782273603 , partial gini =  0.7994033225624675\n",
      "K =  8 , auc =  0.8850633137149991 , brier score =  0.8855491329479769 , partial gini =  0.7701266274299983\n",
      "K =  9 , auc =  0.8906082714646892 , brier score =  0.8905165767154973 , partial gini =  0.7812165429293785\n",
      "K =  10 , auc =  0.8931371219475056 , brier score =  0.8928296067848882 , partial gini =  0.7862742438950112\n",
      "\n",
      "***  MLP with Three hidden layers - MLP3  ***\n",
      "\n",
      "AUC : 0.888 (0.007)\n",
      "Brier Score : 0.888 (0.007)\n",
      "Partial Gini : 0.776 (0.015)\n"
     ]
    }
   ],
   "source": [
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "    \n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    model = KerasClassifier(model=create_model_three_hidden_layers, epochs=10, batch_size=64, verbose=0)\n",
    "    # Grid of parameters to choose from\n",
    "    units = [5, 10, 15, 20]\n",
    "    # dropout_rate = [0, 0.25, 0.5] \n",
    "    dropout_rate = [0]\n",
    "    # L2 = [0.1, 0.01, 0.001, 0] \n",
    "    L2 = [0.1]\n",
    "    # batch_normalization = [\"yes\", \"no\"] \n",
    "    batch_normalization = [\"no\"]\n",
    "    learning_rate = [0.01, 0.001, 0.0001] #learning_rate = [0.01]\n",
    "    param_grid = dict(model__units_1 = units, model__units_2 = units, model__units_3 = units,\n",
    "                  model__dropout_rate = dropout_rate,\n",
    "                 model__batch_normalization = batch_normalization, \n",
    "                 optimizer__learning_rate=learning_rate, \n",
    "                 model__L2 = L2)\n",
    "    # Running the grid search\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_inner, refit=True)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model_3_2 = grid_result.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat =  model_3_2.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the results\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1\n",
    "\n",
    "df_acc_kfold[\"MLP - MLP3\"]=result_acc\n",
    "df_brier_kfold[\"MLP - MLP3\"]=result_brier\n",
    "df_gini_kfold[\"MLP - MLP3\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  MLP with Three hidden layers - MLP3  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3  Model 3-3 : MLP with Five hidden layers - MLP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_five_hidden_layers(units_1,units_2,units_3,units_4, units_5, dropout_rate, L2, batch_normalization = \"yes\"):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units = units_1, kernel_regularizer=l2(l=L2)))\n",
    "    model.add(Dense(units = units_2, kernel_regularizer=l2(l=L2)))\n",
    "    model.add(Dense(units = units_3, kernel_regularizer=l2(l=L2)))\n",
    "    model.add(Dense(units = units_4, kernel_regularizer=l2(l=L2)))\n",
    "    model.add(Dense(units = units_5, kernel_regularizer=l2(l=L2)))\n",
    "    if batch_normalization == \"yes\":\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.8913035859394678 , brier score =  0.8913294797687861 , partial gini =  0.7826071718789356\n",
      "K =  2 , auc =  0.886414303549135 , brier score =  0.8863198458574181 , partial gini =  0.77282860709827\n",
      "K =  3 , auc =  0.8820746030689978 , brier score =  0.8820809248554913 , partial gini =  0.7641492061379955\n",
      "K =  4 , auc =  0.8743562541505643 , brier score =  0.874373795761079 , partial gini =  0.7487125083011286\n",
      "K =  5 , auc =  0.887858136531738 , brier score =  0.8878612716763006 , partial gini =  0.7757162730634759\n",
      "K =  6 , auc =  0.8862369511834371 , brier score =  0.8863198458574181 , partial gini =  0.7724739023668743\n",
      "K =  7 , auc =  0.8909119927528478 , brier score =  0.8905587668593449 , partial gini =  0.7818239855056957\n",
      "K =  8 , auc =  0.8773363652577135 , brier score =  0.8770712909441233 , partial gini =  0.754672730515427\n",
      "K =  9 , auc =  0.8839416761334756 , brier score =  0.8839629915188898 , partial gini =  0.7678833522669513\n",
      "K =  10 , auc =  0.8948305068615696 , brier score =  0.8936006168080185 , partial gini =  0.7896610137231392\n",
      "\n",
      "***  MLP with Five hidden layers - MLP5  ***\n",
      "\n",
      "AUC : 0.886 (0.006)\n",
      "Brier Score : 0.885 (0.006)\n",
      "Partial Gini : 0.771 (0.012)\n"
     ]
    }
   ],
   "source": [
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    model = KerasClassifier(model=create_model_five_hidden_layers, epochs=10, batch_size=64, verbose=0)\n",
    "    # Grid of parameters to choose from\n",
    "    units = [5, 10, 15, 20]\n",
    "    #dropout_rate = [0, 0.25, 0.5]\n",
    "    dropout_rate = [0]\n",
    "    #L2 = [0.1, 0.01, 0.001, 0]\n",
    "    L2 = [0.1]\n",
    "    #batch_normalization = [\"yes\", \"no\"]\n",
    "    batch_normalization = [\"no\"]\n",
    "    #learning_rate = [0.01, 0.001, 0.0001]\n",
    "    learning_rate = [0.01]\n",
    "    param_grid = dict(model__units_1=[15], model__units_2=[15], model__units_3=[20], model__units_4=units, model__units_5=units,\n",
    "                  model__dropout_rate = dropout_rate,\n",
    "                 model__batch_normalization = batch_normalization, \n",
    "                 optimizer__learning_rate=learning_rate, \n",
    "                 model__L2 = L2)\n",
    "    # Running the grid search\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_inner, refit=True)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model_3_3 = grid_result.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_3_3.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the results\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1    \n",
    "    \n",
    "df_acc_kfold[\"MLP - MLP5\"]=result_acc\n",
    "df_brier_kfold[\"MLP - MLP5\"]=result_brier\n",
    "df_gini_kfold[\"MLP - MLP5\"]=result_gini\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  MLP with Five hidden layers - MLP5  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Deep Learning - LSTM & CNN\n",
    "#### 5.4.1 Model 4-1 : LSTM - with one LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Flatten, LSTM, Activation, Input, Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "\n",
    "def create_one_lstm_layer(units):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = units, return_sequences=False, input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.7997254470544068 , brier score =  0.7996146435452793 , partial gini =  0.5994508941088137\n",
      "K =  2 , auc =  0.8123105047262351 , brier score =  0.8111753371868979 , partial gini =  0.6246210094524702\n",
      "K =  3 , auc =  0.7870327358181222 , brier score =  0.7861271676300579 , partial gini =  0.5740654716362443\n",
      "K =  4 , auc =  0.8358449568935304 , brier score =  0.8358381502890173 , partial gini =  0.6716899137870609\n",
      "K =  5 , auc =  0.7887937435328416 , brier score =  0.7888246628131022 , partial gini =  0.5775874870656832\n",
      "K =  6 , auc =  0.7938162241919445 , brier score =  0.7942196531791907 , partial gini =  0.5876324483838891\n",
      "K =  7 , auc =  0.8195095332862553 , brier score =  0.8211946050096339 , partial gini =  0.6390190665725106\n",
      "K =  8 , auc =  0.8126404494382022 , brier score =  0.8115606936416185 , partial gini =  0.6252808988764045\n",
      "K =  9 , auc =  0.8180660601964221 , brier score =  0.818041634541249 , partial gini =  0.6361321203928443\n",
      "K =  10 , auc =  0.8113401473191344 , brier score =  0.8099460292983809 , partial gini =  0.6226802946382688\n",
      "\n",
      "***  DL with one LSTM layer - LSTM1  ***\n",
      "\n",
      "AUC : 0.808 (0.015)\n",
      "Brier Score : 0.808 (0.015)\n",
      "Partial Gini : 0.616 (0.029)\n"
     ]
    }
   ],
   "source": [
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # splitting the data\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configuring the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    model = KerasClassifier(model=create_one_lstm_layer, epochs=10, batch_size=64, verbose=0)\n",
    "    # Grid of parameters to choose from\n",
    "    units = [10, 20, 50]\n",
    "    param_grid = dict(model__units=units)\n",
    "    # Running the grid search\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_inner, refit=True)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model_4_1 = grid_result.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_4_1.predict(X_test)\n",
    "    # evaluating the model\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # storing the results\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1\n",
    "    \n",
    "df_acc_kfold[\"DL - LSTM1\"]=result_acc\n",
    "df_brier_kfold[\"DL - LSTM1\"]=result_brier\n",
    "df_gini_kfold[\"DL - LSTM1\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  DL with one LSTM layer - LSTM1  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 Model 4-2 : CNN1 + LSTM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_conv_2_lstm_layers(filters):\n",
    "    inputs = Input(shape = (X_train.shape[1],1,))\n",
    "    x = Conv1D(filters = filters, kernel_size = 3, padding = 'same', activation = 'relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size = 2, padding = 'same')(x)\n",
    "    x = LSTM(128, return_sequences = True)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    outputs = Dense(1,activation ='sigmoid')(x)\n",
    "    model = Model(inputs = inputs,outputs = outputs)\n",
    "    model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  1 , auc =  0.8693215298931252 , brier score =  0.8697495183044316 , partial gini =  0.7386430597862503\n",
      "K =  2 , auc =  0.8725610843588372 , brier score =  0.8736030828516378 , partial gini =  0.7451221687176743\n",
      "K =  3 , auc =  0.8844727031226982 , brier score =  0.8840077071290944 , partial gini =  0.7689454062453964\n",
      "K =  4 , auc =  0.8847654834613004 , brier score =  0.8847784200385357 , partial gini =  0.7695309669226007\n",
      "K =  5 , auc =  0.8751741900533767 , brier score =  0.8751445086705203 , partial gini =  0.7503483801067534\n",
      "K =  6 , auc =  0.8741210203114251 , brier score =  0.874373795761079 , partial gini =  0.7482420406228503\n",
      "K =  7 , auc =  0.8829185480016833 , brier score =  0.8832369942196532 , partial gini =  0.7658370960033667\n",
      "K =  8 , auc =  0.8797708221865526 , brier score =  0.8805394990366089 , partial gini =  0.7595416443731051\n",
      "K =  9 , auc =  0.8843402629781482 , brier score =  0.8843484965304549 , partial gini =  0.7686805259562963\n",
      "K =  10 , auc =  0.8945830716229849 , brier score =  0.8932151117964533 , partial gini =  0.7891661432459698\n",
      "\n",
      "***  DL with one CNN and 2 LSTM layers - CNN1&LSTM2  ***\n",
      "\n",
      "AUC : 0.880 (0.007)\n",
      "Brier Score : 0.880 (0.007)\n",
      "Partial Gini : 0.760 (0.014)\n"
     ]
    }
   ],
   "source": [
    "# Nested Cross-Validation was used in this study to both tune and evalute the model\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "result_acc = []\n",
    "result_brier = []\n",
    "result_gini = []\n",
    "\n",
    "k=1\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # configuring the cross-validation procedure\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # configure the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    # defining the model\n",
    "    model = KerasClassifier(model=create_one_conv_2_lstm_layers, epochs=10, batch_size=64, verbose=0)\n",
    "    # Grid of parameters to choose from\n",
    "    filters = [10, 20, 50]\n",
    "    param_grid = dict(model__filters=filters)\n",
    "    # Running the grid search\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_inner, refit=True)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    model_4_2 = grid_result.best_estimator_\n",
    "    # evaluating the model on the hold out dataset\n",
    "    yhat = model_4_2.predict(X_test)\n",
    "    # storing the results\n",
    "    acc, brier, gini = get_scores(y_test, yhat)\n",
    "    # store the result\n",
    "    result_acc.append(acc)\n",
    "    result_brier.append(brier)\n",
    "    result_gini.append(gini)\n",
    "    print(\"K = \", k, \", auc = \", acc, \", brier score = \", brier, \", partial gini = \", gini)\n",
    "    k+=1\n",
    "    \n",
    "df_acc_kfold[\"DL - CNN1&LSTM2\"]=result_acc\n",
    "df_brier_kfold[\"DL - CNN1&LSTM2\"]=result_brier\n",
    "df_gini_kfold[\"DL - CNN1&LSTM2\"]=result_gini\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"\\n***  DL with one CNN and 2 LSTM layers - CNN1&LSTM2  ***\\n\")\n",
    "print('AUC : %.3f (%.3f)' % (np.mean(result_acc), np.std(result_acc)))\n",
    "print('Brier Score : %.3f (%.3f)' % (np.mean(result_brier), np.std(result_brier)))\n",
    "print('Partial Gini : %.3f (%.3f)' % (np.mean(result_gini), np.std(result_gini)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#00008B'> 6. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Comparing the Models regarding AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Comparing the Models regarding Brier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Comparing the Models regarding Partial Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Comparing the Models regarding the Average Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
